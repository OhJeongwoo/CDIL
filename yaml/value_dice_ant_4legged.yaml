# experiment description
exp_name: 'ant_4legged'
n_episode: 1000

exp_policy_file_name: 'ac_best'
exp_demo_file_name: 'ant_4legged'
lea_policy_file_name: 'reacher_2dof_corner'
lea_demo_file_name: 'reacher_2dof_corner_copy'

# environment description
exp_env_name: 'Ant_4legged-v0'
lea_env_name: 'Reacher2DOFCorner-v0'
exp_epi_len: 1000
lea_epi_len: 60
exp_goal: True
exp_goal_offset: 0
exp_goal_dim: 2
lea_goal: True
lea_goal_offset: 0
lea_goal_dim: 2

# architecture description
pi_hidden_layers: [256, 256]

# option
# 0-element: batchnorm ('batch-norm' means we use batch normalization)
# 1-element: activation function ('relu', 'leaky-relu', 'sigmoid', 'tanh')
# 2-element: last activation function ('default' means nothing, 'sigmoid', 'tanh')
pi_options: ['default', 'leaky-relu', 'default']


# training description
learning_rate: 0.001
epochs: 1000
steps_per_epoch: 4000
batch_size: 256
iter_size: 128
n_log_epi: 10
save_interval: 10
replay_size: 1000000
steps_per_epoch: 4000
gamma: 0.99
polyak: 0.995
alpha: 0.1
start_steps: 10000
update_after: 1000
update_every: 50
seed: 1
